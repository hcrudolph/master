\subsection{Symbolic Model Checking and First-Order Logic}
\label{ssec:symbolic}

At its core, symbolic model checking describes the verification of a given system represented by a model of system states – a security protocol is essentially a distributed, concurrent system – against a temporal logic formula.
The model can be, for example, a Finite-State Machine (see \cite{alur1998model}), or a Binary Decision Diagram (see \cite{burch1992symbolic}), that captures the number of reachable states and transitions between them.
System states are modeled in an abstract manner by symbols that represent information available to the participants at a given point in time.
State transitions describe how the systems moves from one state into another, the precondition for it happening and the result of the transition.
The temporal logic formula details the intended system requirements in a mathematical way.
The act of model checking is the exploration of all system states, verifying whether or not the formula holds true for all possible scenarios.
An issue is discovered if the provided model does not accurately match the formula – hence the term 'model checking'.
In practice, there exists a number of optimizations to make the task of exploring all system states more efficient than a brute-force search (see \cite{etessami2000optimizing}).
If these operations are performed by a computer, it is considered automatic model checking.
Most model checkers, including the ones that are considered in this thesis, build on some subset of \gls{fol}, which shall be briefly introduced hereafter.
These fundamental concepts are key to understand what kind of system properties are in scope of the following analysis.

%Literature:
%\begin{enumerate}
%    \item \cite{schoning2008logic}
%\end{enumerate}

First-Order Logic (also referred to as predicate logic) extends classical, propositional logic by the notion of predicates and quantifiers.
Whereas the latter is solely concerned with logical statements and connectives, first-order logic is inherently connected to a domain of discourse or universe and the semantics associated with it.
For example, propositional logic is only able to express binary relations using atomic formulas (or symbols), logical connectives (or functions), and formulas that combine symbols and functions according to the logic's particular grammar:

\begin{equation*}
    \begin{gathered}
        \textit{"If it is sunny, it is not raining."}\\
        P \rightarrow \lnot Q
    \end{gathered}
\end{equation*}

A First-Order Logic on the other hand is comprised quantified of symbols, functions, as well as propositions (or relations) between these elements.
Functions and relations are not necessarily binary but can take any number of parameters greater than zero.

\begin{equation*}
    \begin{gathered}
        \textit{"All humans have mothers and John is human. Therefore, John has a mother."}\\
        (\forall x)(Hx \rightarrow Mx) \wedge (Hj) \rightarrow (Mj)
    \end{gathered}
\end{equation*}
\begin{equation*}
    \text{where }
    Mx: x \text{ has a mother; }
    Hx: x \text{ is human; }
    j: \text{constant 'John'}
\end{equation*}

Or

\begin{equation*}
    \begin{gathered}
        \textit{"There exists x such that x is John's mother and x is female."}\\
        (\exists x)(Mxj \wedge Fx)
    \end{gathered}
\end{equation*}
\begin{equation*}
    \text{where }
    Mxy: x \text{ is the mother of y; }
    Fx: x \text{ is female; }
    j: \text{ constant 'John'}
\end{equation*}

\gls{fol} is defined relative to a \textit{signature}, i.e. a set of symbols not inherent to classical logic, by a particular syntax and semantics.
The syntax determines the set of well-formed formulas, whereas the semantics associates meaning to these formulas.
This thesis follows the formal definition of Schöning (c.f. \cite{schoning2008logic}, pp. 41-47), the key points of which are summarized below.

The \gls{fol} syntax is comprised of variables, predicates, functions and quantifiers.
A \textit{variable} is of the form $x_i$ where $i= 1, 2, 3, \ldots$.
A \textit{predicate symbol} is of the form $P_i^k$ and a \textit{function symbol} of the form $f_i^k$ where $i = 1, 2, 3 , \ldots$ and
$k = 0, 1, 2, \ldots$, where $i$ is the index and $k$ is the arity.
A function symbol of arity 0 is also called a \textit{constant}.
A \textit{term} is defined as follows:

\begin{enumerate}
    \item Each variable is a term.
    \item If $f$ is a function symbol with arity $k$, and if $t_1, \ldots, t_k$ are terms, then $f(t_l, \ldots, t_k)$ is a term.
\end{enumerate}

\noindent
Next, \textit{formulas} are defined inductively as follows.

\begin{enumerate}
    \item If $P$ is a predicate symbol with arity $k$, and if $t_1, \ldots ,t_k$ are terms, then $P(t_1 , \ldots, t_k )$ is a formula.
    \item For each formula $F, \lnot F$ is a formula.
    \item For all formulas $F$ and $G$, $(F \wedge G)$ and $(F \vee G)$ are formulas.
    \item If $x$ is a variable and $F$ is a formula, then $\exists xF$ and $\forall xF$ are formulas.
\end{enumerate}

Formulas built according to rule 1 are called \textit{atomic formulas}.
If $F$ is a formula, and $F$ occurs as part of the the formula $G$, then $F$ is called a \textit{subformula} of $G$.
All occurrences of a variable in a formula are distinguished into bound and free occurrences.
An occurrence of the variable $x$ in the formula $F$ is bound if $x$ occurs within a subformula of $F$ of the form $\exists xG$ or $\forall xG$.
A formula without occurrence of a free variable is called a \textit{closed formula} or \textit{sentence}.
The symbol $\exists$ is called the \textit{existential quantifier}.
It denotes its argument holds true sometimes (read: ,,There exists $x, \ldots$'').
The symbol $\forall$ is called the \textit{universal quantifier}.
It denotes its argument holds true everytime (read: ,,For all $x, \ldots$'').

\gls{fol} is defined in relation to a domain of discourse that gives it meaning.
A \textit{structure} is a pair $A = (U_A, I_A)$ where $U_A$ is an arbitrary, non-empty set called the \textit{universe}.
$I_A$ is a mapping that maps

\begin{enumerate}
    \item each $k$-ary predicate symbol $P$ to a $k$-ary predicate on $U_A$ (if $I_A$ is defined on $P$).
    \item each $k$-ary function symbol $f$ to a $k$-ary function on $U_A$ (if $I_A$ is defined on $f$).
    \item each variable $x$ to an element of $U_A$ (if $I_A$ is defined on $x$).
\end{enumerate}

Let $F$ be a formula and $A = (U_A, I_A)$ be a structure.
$A$ is called \textit{suitable} for $F$ if $I_A$ is defined for all predicate symbols, function symbols, and for all variables that occur free in $F$.

Let $F$ be a formula and let $A = (U_A, I_A)$ be a suitable structure for $F$.
For each term $t$ occurring in $F$, its \textit{value} under the structure $A$ is denoted as $A(t)$ and defined inductively as follows.

\begin{enumerate}
    \item If $t$ is a variable $(i.e., t = x)$, then we let $A(t) = x^A$.
    \item If $t$ has the form $t = f(t_1, \ldots, t_k)$ where $t_1, \ldots, t_k$ are terms and $f$ is a function symbol of arity $k$, then we let $A(t) = f^A(A(t_1),\ldots , A(t_k))$.
\end{enumerate}

\begin{enumerate}
    \item If $F$ has the form $F = P( t_1, \ldots, t_k)$ where $t_1, \ldots, t_k$ are terms and $P$ is a predicate symbol of arity $k$, then
    \begin{equation*}
        A(F) =
            \left\{
            \begin{array}{ll}
                  1,& \text{if } (A(t_1), \ldots, A(t_k)) \in P^A \\
                  0,& \text{otherwise}
            \end{array}
            \right.
    \end{equation*}

    \item If $F$ has the form $F= \lnot G$, then
    \begin{equation*}
        A(F) =
            \left\{
            \begin{array}{ll}
                  1,& \text{if } A(G) = 0\\
                  0,& \text{otherwise}
            \end{array}
            \right.
    \end{equation*}

    \item If $F$ has the form $F = (G \wedge H)$, then
    \begin{equation*}
        A(F) =
            \left\{
            \begin{array}{ll}
                  1,& \text{if } A(G) = 1 \text{ and } A(H) = 1\\
                  0,& \text{otherwise}
            \end{array}
            \right.
    \end{equation*}

    \item If $F$ has the form $F = (G \vee H)$, then
    \begin{equation*}
        A(F) =
            \left\{
            \begin{array}{ll}
                  1,& \text{if } A(G) = 1 \text{ or } A(H) = 1\\
                  0,& \text{otherwise}
            \end{array}
            \right.
    \end{equation*}

    \item If $F$ has the form $F = \forall xG$, then
    \begin{equation*}
        A(F) =
            \left\{
            \begin{array}{ll}
                  1,& \text{if for all } u \in U_A, A_{[x/u]}(G) = 1\\
                  0,& \text{otherwise}
            \end{array}
            \right.
    \end{equation*}
\end{enumerate}

If for a formula $F$ and a suitable structure $A$ the term $A(F) = 1$ holds, then this is denoted by $A \models F$ (read $A$ \textit{models} $F$).
If every suitable structure for $F$ is a model for $F$, then this is denoted by $\models F$ (read $F$ is \textit{valid}).
If there is at least one model for the formula $F$ then $F$ is called \textit{satisfiable}, and otherwise \textit{unsatisfiable}.

Translating this definition into the particular example at hand, first the \gls{prins} protocol is to be transposed into formal a structure $A$ (,,the model'').
Secondly, a formula $F$ has to be defined for each of the desired security properties in order to be able to validate it against $A$.
If a model checker is able to prove that $F$ is valid for $A$, the related property is considerd successfully verified.
Given the nature of this approach to proving a system's correctness, model checking is only able to assess a particular set of properties.
That is, only logical correctness can effectively be verified.

\subsubsection{Safety Properties}

Safety properties, particularly in the context of security protocols, can informally be described as the absence of something bad happening.
A trivial example is secrecy: No unauthorized party is supposed to have access to sensitive data in the clear.
These properties are specified over a particular order of states (or \textit{traces}) the modeled system is going through and may be broken by a finite run that leads to an undesired state.
Such cases, in which the reachability of a certain bad state falsifies the property are called \textit{invariants}.
Checking for this particular type of flaw is simply a matter of verifying whether a given furmula holds for all reachable states.
More formally, invariants can be defined as follows (c.f. \cite{baier2008principles}, p. 107).

A property $P_{inv}$ over $A$ is an invariant if there is a first-order logic formula $F$ over $A$ such that

\begin{equation*}
    P_{inv} = \{ A_0, A_1, A_2, \ldots \in (A)^\omega | \forall j \geq 0. A_j \models F \}
\end{equation*}

\noindent
$F$ is called an invariant condition (or state condition) of $P_{inv}$.

In addition to invariants, there exist safety properties that are more involved than just the absence of certain undesired states.
Instead, these may impose requirements on parts of the system's execution trace itself.
Consider, for example, an arbitrary security protocol that would allow sending data prior to performing the cryptogrtaphic operations that ensure integrity or confidentiality.
Even though this trivial case would likely already be discoverd during modeling phase, it examplifies that the order of subsequent states is relevant.
That is, these type properties is not about guaranteeing the reachability of ,,bad'' states, but ,,bad'' path fragments in the execution trace.
Such safety properties are a generalization of invariantes and are fullfilled if there is no execution trace contains a finite prefix that violates the premise.
They can be defiend as follows (c.f. \cite{baier2008principles}, p. 112).

A property $P_{safe}$ over $A$ is called a safety property if for all words $\sigma \in (2^{A})^{\omega} \in P_{safe}$ there exists a finite prefix $\widehat{\sigma}$ of $\sigma$ such that

\begin{equation*}
    P_{safe} \cap \{ \sigma' \in (2^{A})^{\omega} | \widehat{\sigma} \text{ is a finite prefix of } \sigma' \} = \emptyset
\end{equation*}

\noindent
Any such finite word $\widehat{\sigma}$ is called a bad prefix for $P_{safe}$.

Some of the relevant features of security protocols that can be expressed using safety properties include confidentiality, integrity, and authentication.

\subsubsection{Liveliness Properties}

Complementary to the abovementioned characteristics are properties that demand something good eventually always happening.
Unlike safety properties, they do not impose requirements on finite traces of the system, but put conditions on the infinite behaviour.
A formal definition can be given as follows (c.f. \cite{baier2008principles}, p. 121).

Property $P_{live}$ over $A$ is a liveness property whenever $pref(P_{live}) = (2^{A})\star$.
Thus, a liveness property (over $A$) is a property $P$ such that each finite word can be extended to an infinite word that satisfies $P$.
Stated differently, $P$ is a liveness property if and only if for all finite words $w \in (2^{A})\star$ there exists an infinite word $\sigma \in (2^{A})^\omega$ satisfying $w \sigma \in P $.

Concrete examples for liveness properties are recovery, revocation, and the timeliness of certain actions.

\subsubsection{Indistinguishability}

The above definitions for both safety and liveliness are closely linked to the concept of traces, i.e. individual system runs that satisfy or violate certain conditions.
There exisits yet another type of properties that is not defined over individual traces, but the information an attacker is able to obtain by observing multiple instances of the system.
This is commonly referred to as \textit{indistinguishability} or \textit{observational equivalence}.
The formal definition is given below (c.f. \cite{baier2008principles}, pp. 589-590).

Let $TS_1$ and $TS_2$ be two transition systems over $A$ with state spaces $S_1$ and $S_2$ , respectively.
A binary relation $R \subseteq S_1 \times S_2$ is an
observational bisimulation for ($TS_1$ , $TS_2$) if and only if the following conditions are satisfied:

\begin{enumerate}[label=(\Alph*)]
    \item Every initial state of $TS_1$ is related to an initial state of $TS_2$, and vice versa. That is
    \begin{equation*}
        \forall s_1 \in I_1 \exists s_2 \in I_2. (s_1, s_2) \in R \text{ and } \forall s_2 \in I_2 \exists s_1 \in I_1. (s_1, s_2) \in R
    \end{equation*}
    \item For all $(s_1, s_2) \in R$ the following conditions (1), (2) and (3) hold:
    \begin{enumerate}[label=(\arabic*)]
        \item If $(s_1, s_2) \in R$ then $L_1 (s_1) = L_2 (s_2)$
        \item If $(s_1, s_2) \in R$ and $s'_1 \in Post(s_1)$ then there exists a path fragment $u_0 u_1 \ldots u_n$ such that $n \geq 0$ and $u_0 = s_2, (s'_1, u_n) \in R$ and, for some $m \leq n, L_2(u_0) = L_2(u_1) = \ldots = L_2(u_m)$ and $L_2(u_{m+1}) = L_2(u_{m+2}) = \ldots = L_2(u_n)$.
        \item If $(s_1, s_2) \in R$ and $s'_2 \in Post(s_1)$ then there exists a path fragment $u_0 u_1 \ldots u_n$ such that $n \geq 0$ and $u_0 = s_2, (u_n, s'_2) \in R$ and, for some $m \leq n, L_1(u_0) = L_1(u_1) = \ldots = L_1 (u_m )$
and $L_1(u_{m+1}) = L_1(u_{m+2}) = \ldots = L_1 (u_n)$.
    \end{enumerate}
\end{enumerate}

\noindent
$TS_1$ and $TS_2$ are called observational equivalent, denoted $TS_1 \approx_{obs} TS_2$, if there exists an observational bisimulation for $(TS_1, TS_2)$.

\subsection{Tamarin}
\label{ssec:tamarin}

The \textsc{Tamarin} prover is a tool for automated formal verification in the symbol model.
Initially developed by Meier and Schmidt at ETH Zürich (see \cite{schmidt2012formal}, \cite{meier2013advancing}), its primary domain of application is the analysis of security protocols.
\textsc{Tamarin} enjoys notable popularity since its creation, with some of the protocols verified using the tool cited on its official website (c.f. \cite{tamarin}), such as TLS 1.3 (\cite{cremers2017comprehensive}), CoAP and MQTT (\cite{kim2017automated}), and 5G AKA (\cite{basin2018formal}).

The security protocol under test is specified in \textsc{Tamarin}'s custom syntax and internally represented as \glspl{mrs}.
Security properties to be verified are written as two-sorted first-order logic formulas, i.e. formulas considering terms of two types: protocol messages and timepoints.
It features built-in support for the aforementioned Dolev-Yao adversaries, but has also been extended to incorporate stronger attackers such as the \gls{eck} model (see \cite{lamacchia2007stronger}).
In the following, an overview of the \textsc{Tamarin} prover's key concepts is provided as well as a survey of its current feature set and limitations.

\subsubsection{Terminology}

\textbf{State} is modeled as a multiset, i.e. a set of sets, of facts.
Facts are built of terms over a fact signature $\Sigma_{Fact}$ and have the form $F(t_1, \ldots, t_k)$.
They can either be linear or persistent.
As Meier explains (\cite{meier2013advancing}, p. 76): ,,Linear facts model resources that can only be consumed once, whereas persistent facts model inexhaustible resources that can be consumed arbitrarily often.''
The finite multiset of all facts represents the system state, including the adversary knowledge.

\textbf{Rules} are used to describe transitions between system states.
Multiset rewriting rules are of the form $l \tracerule{a} r$, where a multiset of facts $l$ is replaced by a multiset of facts $r$ using an action $a$.
Such rule is applicable to a given state $S$ if it contains the same linear and persistent facts as $S$.
In order to transition into a successor state $S'$, all linear facts are removed and facts generated by action $a$ are added.

\noindent
A protocol \textit{execution} is defined by an alternating sequence of states and rules. The initial state $S_0$ is always the empty multiset.

\begin{equation}\label{eq:execution}
    e = [S_0, (l_1 \tracerule{a_1} r_1), S_1, \ldots, S_{k-1}, (l_k \tracerule{a_k} r_k), S_k]
\end{equation}

\noindent
Based on above definition, the \textit{trace} of a protocol execution is described by the sequence of actions to get from the initial to the final state.

\begin{equation}
    trace(e) = [set(a_1), \ldots, set(a_k)]
\end{equation}

\noindent
This is key for describing certain safety properties on the basis of traces, as shown in the previous section.

\textbf{Adversaries} are implicitly modelled within the multiset rewriting system of the protocol itself.
In order to do so, \textsc{Tamarin} uses a few special fact symbols reserved for particular use cases.

\begin{enumerate}[label=--]
    \item \textsf{Fr(x)} denotes a fresh name $x$ that is unique and unguessable. This capability is required for the concept of random values or nonces, which are a common component of security protocols.
    \item \textsf{K(x)} denotes the adversary's knowledge of $x$, i.e. $x$ is revealed.
    \item \textsf{Out(x)} denotes sending a message $x$ via the public Dolev-Yao channel. Recall that once this is done, the adversary can read, modify, or block any contained information.
    \item \textsf{In(x)} denotes receiving a message $x$ via the public channel and thus, by the adversary.
\end{enumerate}

\noindent
Based on these unary fact symbols, \textsc{Tamarin} defines a set of message deduction rules (c.f. \cite{meier2013advancing}, p. 78).
These allow the adversary send and receive messages on the public channel, learn about freshly generated names and public constants, and apply arbitrary functions on the messages observed.

\begin{equation*}
    \textsf{MD} = \left\{
        \begin{aligned}
            \textsf{Out(x)} &\ltracerule\rtracerule \textsf{K(x)}\\
            \textsf{K(x)} &\tracerule{\textsf{K(x)}} \textsf{In(x)}\\
            \textsf{Fr(x)} &\ltracerule\rtracerule \textsf{K(x)}\\
            [] &\ltracerule\rtracerule \textsf{K(x:pub)}\\
            \textsf{(K(}x_1\textsf{)}, \ldots, \textsf{K(}x_k\textsf{))} &\ltracerule\rtracerule \textsf{K(}f(x_1, \ldots, x_k) | f \in \Sigma^k\textsf{)}
        \end{aligned}
    \right\}
\end{equation*}

\subsubsection{Security properties} 

In \textsc{Tamarin} security properties are denoted using two-sorted first-order logic formulas over message terms and timepoints (c.f. \cite{meier2013advancing}).
These so-called lemmas allow for the specification of various trace properties as well as some forms of observational equivalence.
As shown in section \ref{sec:formal}, one of the most common use case of trace properties as far as security protocols are concerned is specifying secrecy (recall that invariants are simply a special form of trace properties).
Secrecy in \textsc{Tamarin} can be expressed using the following lemma, stating that for any secret action $x$ at timepoint $i$, there exsists no timepoint $j$ at which the adversary has knowledge about $x$.
The very last line is added to ensure satisfiability of the lemma in the face of a potential key compromise of an honest participant $B$ at timepoint $r$.
Beyond this basic secrecy property, the tool further offers support for perfect forward secrecy. (see \cite{tamarin2019manual}, pp. 71-72)

\lstset{
    basicstyle=\small\sffamily,
    keywordstyle=\bfseries,
    frame=tb,
    morekeywords={lemma, All, Ex, Reveal, Honest, Create, Running, Secret},
}
\begin{lstlisting}
lemma secrecy:
    "All x #i.
        Secret(x) @i ==>
        not (Ex #j. K(x) @j)
            | (Ex B #r. Reveal(B) @r & Honest(B) @i)"
\end{lstlisting}

Trace properties are also used to specify authentication between protocol participants.
As \cite{lowe1997hierarchy} shows, there are several ways to define authentication that vary greatly in stictness.
With the exception of \textbf{Recentness}, \textsc{Tamarin} can model the following four types of authentication (see \cite{tamarin2019manual}, pp. 74-75).
\textbf{Aliveness} mandates that if participant $a$ completes a protocol run at timepoint $i$, there exists a participant $b$ that has previously run the protocol.
Intuitively, this is a rather weak premise that is not useful for varifying the \gls{prins} protocol.

\begin{lstlisting}
lemma aliveness:
    "All a b t #i.
        Commit(a,b,t) @i
        ==>  (Ex id #j. Create(b,id) @j)
            | (Ex C #r. Reveal(C) @r & Honest(C) @i)"
\end{lstlisting}

\textbf{Weak agreement} specifies that if participant $a$ completes a protocol run at timepoint $i$, there exists a participant $b$ that has previously run the protocol with $a$.

\begin{lstlisting}
lemma weak_agreement:
    "All a b t1 #i. 
        Commit(a,b,t1) @i
        ==> (Ex t2 #j. Running(b,a,t2) @j)
            | (Ex C #r. Reveal(C) @r & Honest(C) @i)"
\end{lstlisting}

\textbf{Non-injective agreement} mandates that if participant $a$ completes a protocol run at timepoint $i$, there exists a participant $b$ that has previously run the protocol with $a$ and both participants agreed on a message term $t$.

\begin{lstlisting}
lemma noninjective_agreement:
    "All a b t #i. 
        Commit(a,b,t) @i
        ==> (Ex #j. Running(b,a,t) @j)
            | (Ex C #r. Reveal(C) @r & Honest(C) @i)"
\end{lstlisting}

\textbf{Injective agreement} specifies that if participant $a$ completes a protocol run at timepoint $i$, there exists a participant $b$ that has previously run the protocol with $a$ and both participants agreed on a message term $t$.
Furthermore, there exisits a one-to-one relationship between the number of protocol executions by $a$ and $b$.

\begin{lstlisting}
lemma injective_agreement:
    "All A B t #i. 
        Commit(A,B,t) @i
        ==> (Ex #j. Running(B,A,t) @j
        & j < i
        & not (Ex A2 B2 #i2. Commit(A2,B2,t) @i2 & not (#i2 = #i)))
            | (Ex C #r. Reveal(C) @r & Honest(C) @i)"
\end{lstlisting}

In addition to trace properties, \textsc{Tamarin} is also able to prove observational equivalence using the \textsf{\textbf{diff}} operator introduced by \cite{basin2015automated}.
The underlying idea is to check whether two multiset rewriting system exhibit identical rules but vary only by their instanciation, i.e. by the valuation of their variables.
If it would be possible to apply different rules in one of the systems that are not available in the other, the adversary would be able to distinguish the two.
Internally, \textsc{Tamarin} duplicates the model and checks whether every rule execution in one instanciation has a corresponding rule execution in thre other one.
This type of check is particularly relevant for proving privacy properties, for example in e-voting protocols. (see \cite{tamarin2019manual}, pp. 57-64)

\subsubsection{Featureset \& Limitations}

As established previously, \textsc{Tamarin} offers support for a range of trace properties that allow for the specification of common secrecy, authentication, and privacy goals.
On top of that, it provides a number cryptographic primitives built-in that are commonly used in security protocols: hashes, signatures, symmetric and asymmetric encryption, diffie-hellman groups, bilinear groups, XOR operations, and multisets. 
The first three of these are of relevance to the \gls{prins} protocol, as hash functions and symmetric encryption are key for defining \gls{jwe}'s \gls{aead} encryption scheme and digital signatures are the core of \gls{jws}.
Additional language features to optimize the formal verification include various channel properties (Dolev-Yao, authentic, confidential, and secure channels), various heuristics to optimize automated proof methods, and induction.

In its current version, \textsc{Tamarin} does not support blind signatures and trapdoor commitments, i.e. non-subterm-convergent theories, although there are extensions that tackle specificly those (see \cite{dreier2017beyond}).
Since neither of these properties is required for the \gls{prins} protocol, this does not hinder our verification in any way.
When operated in observational equivalence mode, the tool is sound, but not complete. (\cite{tamarin2019manual}, p. 107)

\subsection{ProVerif}
\label{ssec:proverif}

\textsc{ProVerif} is another example for a popular tool for symbolic model checking.
Chiefly developed by Bruno Blanchet at INRIA Paris, it is one of the most mature model checking tools in existence, being actively maintained for almost 20 years.
Like \textsc{Tamarin}, it has successfully been used to analyse a wide range of security protocols over the years.
Examples cited on its official website include (c.f. \cite{proverif}) the Signal protocol (\cite{kobeissi2017automated}), the ARINC823 avionic protocols (\cite{blanchet2017symbolic}), and the FOO, Lee, JCJ, and Belenios e-voting protocols (\cite{hirschi2019improving}).

Compared to the \textsc{Tamarin} prover, \textsc{ProVerif} tackles the problem of verifying security protocols distinctly different.
Protocols are specified in the applied pi calculus (see \cite{abadi2017applied}), a variant of the pi calculus originally proposed by Milner (\cite{milner1999communicating}), a process algebra that is used to formally describe the behavior of security protocols.
It extends the latter by components such as fresh variables and functions that model cryptographic primitives, to make it more suitable for this particular purpose.

\subsubsection{Terminology}

The \textbf{applied pi calculus} and process algebras in general are a formal method for describing the behavior of concurrent systems.
As Baeten et al. point out: ,,A process algebra can be defined as any mathematical structure satisfying the axioms given for the basic operators'' (\cite{baeten2007process}, p. 1).
The term ,,process'' is to be understood as an abstract element of this model.
The fact that it is an ,,algebra'' signals that algebraic rules apply.
Accordingly, calculations on processes can be performed using the defined operators in a given algebra.
In the applied pi calculus used in \textsc{ProVerif}, operators are refered to as expressions.
Expressions perform computations on terms, representing data or messages that are exchanged between processes.
Processes are build from terms and expressions.
Processes are used to model protocol participants, the Dolev-Yao adversary, as well as the protocol under test itself.

\textbf{Terms} are built up from names, variables and constructors.
While names represent atomic data, variables are a placeholder for other terms and can be replaced by such.
Constructors are functions with a certain arity used to build terms.
All three kinds of terms are defined with a type.
The default types defiend by \textsc{ProVerif} are \textsf{channel}, \textsf{boolean}, and \textsf{bitstring}, but the tool also supports custom types.

\lstset{
    mathescape,
    emph={D,M,N,P,Q,T,x,y,z,a,b,c,h,k,s,f},
    emphstyle=\itshape
}
\begin{figure}[h!]
    \centering
    \begin{lstlisting}
        M,N ::=                     term
            x,y,z                       variable
            a,b,c,k,s                   name
            f($M_1,\ldots,M_n$)                         constructor application
    \end{lstlisting}
    \caption{Proverif term grammar, according to \cite{blanchet2016modeling}, p. 13}
    \label{fig:pv-terms}
\end{figure}

\textbf{Expressions} evaluate so-called \textit{may-fail} terms.
That is, their evaluation yields a result that is either a term $M$ or the special constant $fail$, representing a failed computation.
This laguage feature allows for the modeling of complex data types as well as cryptographic primitives, such as encryption which constructs a ciphertext from atomic terms (key and plaintext) and decryption which resolves a \textit{may-fail} term (ciphertext) into the original plaintext, unless it fails.

\begin{figure}[h!]
    \centering
    \begin{lstlisting}
        D ::=                       expression
            M                           term
            f($D_1,\ldots,D_n$)                         constructor application
            g($D_1,\ldots,D_n$)                         destructor application
            fail                        failure
    \end{lstlisting}
    \caption{Proverif expression grammar, according to \cite{blanchet2016modeling}, p. 13}
    \label{fig:pv-expressions}
\end{figure}

\textbf{Processes} in \textsc{ProVerif} largely coincide with processes in the original pi calculs (c.f. \cite{blanchet2016modeling}, p. 18).
They allow for the description of sending and receiving messages, parallel execution, creation of new names, evaluation of expressions, and conditionals.
When verifying security protocols, one process usually represents one protocol participant, incl. the adversary.

\begin{figure}[h!]
    \centering
    \begin{lstlisting}
        P,Q ::=                     process
            0                           nil
            out(N,M);P                  output
            in(N,x:T);P                 input
            P|Q                         parallel composition
            !P                          replication
            new a:T;P                   restriction
            let x:T=D in P else Q       expression evaluation
            if M then P else Q          conditional
    \end{lstlisting}
    \caption{Proverif process grammar, according to \cite{blanchet2016modeling}, p. 13}
    \label{fig:pv-processes}
\end{figure}

Internally, \textsc{ProVerif} translates the applied pi calculus representation of a protocol into a set of \textbf{Horn clauses}.
Horn clauses are a Turing-complete subset of first-order logic commonly used in logic programming and theorem proving.
As stated in \ref{ssec:symbolic}, an atomic formula in predicate logic has the shape $P(t_1, \ldots, t_n)$.
A \textit{literal} $L$ is either an atomic formula or the negation of one.
A \textit{clause} is a disjunction of literals, for example:

\begin{equation}
    L_1 \vee L_2 \vee L_3 \vee \ldots \vee L_n
\end{equation}

\noindent
A \textit{Horn clause} is a clause containing at most one positive literal.
A Horn clause without any negative literals or variables is called a \textit{fact}.
Rather than in disjunctive form, these clauses are used to describe logical implication:

\begin{equation}
    \label{eq:implication}
    \lnot L_1 \vee \lnot L_2 \vee L_3 \Leftrightarrow  \underbrace{L_3}_\text{query} \leftarrow \underbrace{L_1 \wedge L_2}_\text{hypothesis}
\end{equation}

In logic programming and theorem proving, the latter is also called \textit{goal clause}.
Proving $L_3$ is equivalent to finding a solution to the right-hand side of the equation, i.e. its \textit{hypothesis}.
Alternatively, refuting it is a matter of finding a counterexample to the query.
In its internal representation \textsc{ProVerif} effectively uses three types of Horn clauses (c.f. \cite{blanchet2013automatic}, p. 13):

\begin{enumerate}[label=--]
    \item Clauses describing the computation abilities of the adversary, i.e. application of constructors, destructors and generation of fresh names
    \item Facts decribing the initial knowledge of the attacker, such as public keys
    \item A multiset of clauses describing the protocol, containing one set for each message
\end{enumerate}

\subsubsection{Security Properties}

Security properties in \textsc{ProVerif} are specified using queries of a similar form as those introduced in equation \ref{eq:implication}.
That way, the tool is capable of proving basic reachability properties, correspondence assertions, and observational equivalence.
The first category allows for the verification of secrecy by checking whether the fact a given message $M$ is exposed to the adversary is reachable under any circumstances.
This can be denoted in two ways (c.f. \cite{blanchet2020proverif}, p. 55):

\lstset{
    basicstyle=\small\sffamily,
    keywordstyle=\bfseries,
    frame=tb,
    morekeywords={query, attacker, secret, event},
    escapechar=\&
}
\begin{lstlisting}
    query attacker(M) &\lstcomment{// adversary cannot compute M}&
    query secret x &\lstcomment{// adversary cannot compute bound variable x}&
\end{lstlisting}

Correspondence assertions on the other hand are the basis for verifying authentication properties.
As described in the previous section, authentication can be defined in several different ways.
\textsc{ProVerif}'s user manual describes the verification of two of them (\cite{blanchet2020proverif}, pp. 19-20).
The keyword \textsf{\textbf{event}} can be used to annotate special points in a protocol that can then be checked for correspondence, as shown in the below code fragment.
Effectively, this is the equivalent of proving the aforementioned aliveness property, i.e. for every event \textsf{receivedByA} there exists at least one event \textsf{sentByB}.
The injective agreement requirement is expresses in the same way, just with the keyword \textsf{\textbf{inj-event}}.

\begin{lstlisting}
    event receivedByA(M); event sentByB(M);
    query receivedByA(M) ==> sentByB(M)
\end{lstlisting}

\noindent
\textsc{ProVerif} goes beyond these basic correspondence assertions, allowing for the use of conjunctions (\textsf{\&\&}), disjunctions (\textsf{\textbar\textbar}), and nesting in the specification of hypotheses.
Nested hypotheses are equivalent to a chain of logical dependencies of the form (c.f. \cite{blanchet2020proverif}, p. 54):

\begin{lstlisting}
    event A; event B; event C;
    A(x) ==> B(x) ==> C(x) || D(x) &\lstcomment{// A is preceded by B is preceded by C or D}&
\end{lstlisting}

Observational equivalence can take multiple forms, some of which can be verified by \textsc{ProVerif} (c.f. \cite{blanchet2020proverif}, pp. 55-62).
Firstly, it is able to prove strong secrecy, i.e. the indistinguishability of a change in secrets for the adversary, with the \textsf{\textbf{noninterf}} keyword.
Secondly, resistence against offline guessing attacks can be verified with the \textsf{\textbf{weaksecret}} keyword by checking whether the adversary is able to distinguish correct from incorrect guesses of a secret when interacting with the protocol.
Thirdly, observational equivalence of two processes instances implemented based on biprocess simulation similar to \textsc{Tamarin}, using the \textsf{\textbf{choice}} keyword.
Lastly, \textsc{ProVerif} will also attempt to verify observational equivalence of two processes that also differ in their structure.
However, merging different processes into a single biprocess requires at least a similar structure and does not always succeed.

\subsubsection{Featureset \& Limitations}

\textsc{ProVerif} supports the verification of secrecy, authentication and privacy properties, similar to \textsc{Tamarin}.
Unlike \textsc{Tamarin}, queries for weak agreement and non-injective agreement are not built-in and are not explicitly pointed out in the user manual.
However, the tool offers more options for checking various types of observational equivalence.
Whereas \textsc{Tamarin} only features this kind of analysis for a full protocol execution, \textsc{ProVerif}'s \textbf{choice}, \textbf{noninf}, and \textbf{weaksecret} constructs allow for more granular checks. 
The cryptographic primitives supported out of the box are symmetric and asymmetric encryption, probabilistic encryption, hashes, signatures, diffie-hellman groups,
zero-knowledge proofs, and trapdoor commitments ( c.f. \cite{blanchet2020proverif}, pp. 42-51).
As pointed out before, the \gls{prins} protocol makes use of symmetric encryption, hashes, and signatures.
Thus, \textsc{ProVerif} does support modeling all necessary cryptographic operations.
Similar to \textsc{Tamarin}, it also supports proof by induction and channel properties, albeit in a less granular fashion -- public Dolev-Yao channels or private (secure) ones.

Additionally, \textsc{ProVerif} supports basic temporal constructs in the form of \textbf{phases} and \textbf{synchronization}.
When using protocol phases, each has its own security properties and process communication across different phases is forbidden.
If processes have not fully terminated when transitioning from one phase to another, they are discarded. (see \cite{blanchet2020proverif}, pp. 41-42).
Synchronization on the other hand allows for modeling a mandatory order of commands across processes at certain points.
If one process has not executed certain commands prior a point of synchronization yet, it waits (potentially indefinitely) until these are executed.
\textbf{Tables} can be used to model persistent storage of any of the participants that is not accessible by the adversary.